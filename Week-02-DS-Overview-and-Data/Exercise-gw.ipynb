{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall 2024 Data Science Track: Week 2 - Data Cleaning Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages, Packages, Packages!\n",
    "\n",
    "Import *all* the things here! You need the standard stuff: `pandas` and `numpy`.\n",
    "\n",
    "If you got more stuff you want to use, add them here too. 🙂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here.\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "With the packages out of the way, now you will be working with the following data sets:\n",
    "\n",
    "* `food_coded.csv`: [Food choices](https://www.kaggle.com/datasets/borapajo/food-choices?select=food_coded.csv) from Kaggle\n",
    "* `Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`: [Ask A Manager Salary Survey 2021 (Responses)](https://docs.google.com/spreadsheets/d/1IPS5dBSGtwYVbjsfbaMCYIWnOuRmJcbequohNxCyGVw/view?&gid=1625408792) as *Tab Separated Values (.tsv)* from Google Docs\n",
    "\n",
    "Each one poses different challenges. But you’ll―of course―overcome them with what you learned in class! 😉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food Choices Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Food choices data set into a variable (e.g., df_food).\n",
    "\n",
    "food_data_set_path = 'data/food_coded.csv'\n",
    "\n",
    "df_food = pd.read_csv(food_data_set_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 61)\n"
     ]
    }
   ],
   "source": [
    "# Count by hand. (lol kidding)\n",
    "print(df_food.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPA                  object\n",
       "Gender                int64\n",
       "breakfast             int64\n",
       "calories_chicken      int64\n",
       "calories_day        float64\n",
       "                     ...   \n",
       "type_sports          object\n",
       "veggies_day           int64\n",
       "vitamins              int64\n",
       "waffle_calories       int64\n",
       "weight               object\n",
       "Length: 61, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "df_food.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Perhaps we’d like to know more another day, but the team is really interested in just the relationship between calories (`calories_day`) and weight. …and maybe gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you remove the other columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ‘em.\n",
    "# we only want to the columns for calories_day, weight, and gender.\n",
    "# We can drop the rest.\n",
    "df_food = df_food[['calories_day', 'weight','Gender']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about `NaN`s? How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calories_day    19\n",
       "weight           2\n",
       "Gender           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count ‘em.\n",
    "#count the NaN values in the data set.\n",
    "df_food.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gotta remove those `NaN`s―the entire row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calories_day    0\n",
       "weight          0\n",
       "Gender          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop ‘em.\n",
    "#remove all the rows with nan values.\n",
    "df_food = df_food.dropna()\n",
    "df_food.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about the weird non-numeric values in the column obviously meant for numeric data?\n",
    "\n",
    "Notice the data type of that column from when you got the types of all the columns?\n",
    "\n",
    "If only we could convert the column to a numeric type and drop the rows with invalid values. 🤔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories_day</th>\n",
       "      <th>weight</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I'm not answering this.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Not sure, 240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>3.0</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>3.0</td>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>4.0</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2.0</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4.0</td>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     calories_day                    weight  Gender\n",
       "1             3.0                       155       1\n",
       "2             4.0  I'm not answering this.        1\n",
       "3             3.0             Not sure, 240       1\n",
       "4             2.0                       190       1\n",
       "5             3.0                       190       1\n",
       "..            ...                       ...     ...\n",
       "118           3.0                       140       1\n",
       "119           3.0                       185       2\n",
       "120           4.0                       156       1\n",
       "121           2.0                       180       1\n",
       "123           4.0                       135       2\n",
       "\n",
       "[104 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix that.\n",
    "df_food\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories_day</th>\n",
       "      <th>weight</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>3.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>3.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>4.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     calories_day  weight  Gender\n",
       "1             3.0   155.0       1\n",
       "4             2.0   190.0       1\n",
       "5             3.0   190.0       1\n",
       "6             3.0   180.0       2\n",
       "7             3.0   137.0       1\n",
       "..            ...     ...     ...\n",
       "118           3.0   140.0       1\n",
       "119           3.0   185.0       2\n",
       "120           4.0   156.0       1\n",
       "121           2.0   180.0       1\n",
       "123           4.0   135.0       2\n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the weight column to numeric and drop the rows with invalid values.\n",
    "df_food['weight'] = pd.to_numeric(df_food['weight'], errors='coerce')\n",
    "df_food = df_food.dropna()\n",
    "df_food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this data seems reasonably clean for our purposes! 😁\n",
    "\n",
    "Let’s save it somewhere to be shipped off to another teammate. 💾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savey save!\n",
    "#save it as df_food_cleaned.csv\n",
    "df_food.to_csv('data/df_food_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask a Manager Salary Survey 2021 (Responses) Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ask A Manager Salary Survey 2021 (Responses) data set into a variable (e.g., df_salary). It is a tsv file. why.\n",
    "#data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv\n",
    "df_salary = pd.read_csv('data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was that hard? 🙃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename the file to something that is better for all systems.  \n",
    "* No spaces in filename (can use '_')\n",
    "* all lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the file to df_salary.csv\n",
    "df_salary.to_csv('data/df_salary.csv', index=False)\n",
    "df_salary = pd.read_csv('data/df_salary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore\n",
    "\n",
    "You know the drill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28062, 18)\n"
     ]
    }
   ],
   "source": [
    "# Count by hand. I’m dead serious.\n",
    "#no\n",
    "print(df_salary.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp                       object\n",
       "age                             object\n",
       "industry                        object\n",
       "title                           object\n",
       "title_context                   object\n",
       "salary                          object\n",
       "additional_compensation        float64\n",
       "currency                        object\n",
       "other_currency                  object\n",
       "salary_context                  object\n",
       "country                         object\n",
       "state                           object\n",
       "city                            object\n",
       "total_yoe                       object\n",
       "field_yoe                       object\n",
       "highest_education_completed     object\n",
       "gender                          object\n",
       "race                            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "df_salary.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh… Ugh! Give these columns easier names to work with first. 🙄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename ‘em.\n",
    "# Non-binding suggestions: timestamp, age, industry, title, title_context, salary, additional_compensation, currency, other_currency, salary_context, country, state, city, total_yoe, field_yoe, highest_education_completed,\tgender, race\n",
    "#column list time\n",
    "df_salary.columns = ['timestamp', 'age', 'industry', 'title', 'title_context', 'salary', 'additional_compensation', 'currency', 'other_currency', 'salary_context', 'country', 'state', 'city', 'total_yoe', 'field_yoe', 'highest_education_completed', 'gender', 'race']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s a lot, and that should not have been easy. 😏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re going to have a gander at the computing/tech subset first because thats *your* industry. But first, what value corresponds to that `industry`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computing or Tech                          4699\n",
       "Education (Higher Education)               2464\n",
       "Nonprofits                                 2419\n",
       "Health care                                1896\n",
       "Government and Public Administration       1889\n",
       "                                           ... \n",
       "Gaming (Gambling)                             1\n",
       "Regulatory Affairs- nutraceuticals            1\n",
       "Manufacturing : corporate admin support       1\n",
       "Real Estate Investment Support                1\n",
       "Wine & Spirits                                1\n",
       "Name: industry, Length: 1219, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the unique industries and a count of their instances.\n",
    "df_salary['industry'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That value among the top 5 is what you’re looking for innit? Filter out all the rows not in that industry and save it into a new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4702, 18)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtery filter. (Save it to a new variable, df_salary_tech.)\n",
    "#filter the data set to only include rows where the industry is Computing or Tech.\n",
    "#industries = df_salary['industry'].unique()\n",
    "#print(industries)\n",
    "df_salary_tech = df_salary[(df_salary['industry'] == \"Computing or Tech\") | (df_salary['industry'] == \"Tech\") | (df_salary['industry'] == \"Computing\")]\n",
    "df_salary_tech.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a sanity check to make sure that the only values you kept are the one you are filtered for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computing or Tech    4699\n",
       "Tech                    3\n",
       "Name: industry, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check \n",
    "df_salary_tech['industry'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save it as df_salary_tech.csv to make my life easier.\n",
    "df_salary_tech.to_csv('data/df_salary_tech.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#START FROM HERE IF YOU MESS UP BRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary_tech = pd.read_csv('data/df_salary_tech.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are very interested in salary figures. But how many dollars 💵 is a euro 💶 or a pound 💷? That sounds like a problem for another day. 🫠\n",
    "\n",
    "For now, let’s just look at U.S. dollars (`'USD'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3780, 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtery filter for just the jobs that pay in USD!\n",
    "df_salary_tech_usd = df_salary_tech[df_salary_tech['currency'] == 'USD']\n",
    "df_salary_tech_usd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really want know is how each U.S. city pays in tech. What value in `country` represents the United States of America?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States                1576\n",
       "USA                          1225\n",
       "US                            412\n",
       "U.S.                          108\n",
       "United States of America       90\n",
       "United States                  68\n",
       "Usa                            59\n",
       "USA                            56\n",
       "usa                            28\n",
       "United states                  23\n",
       "united states                  14\n",
       "Us                             12\n",
       "us                              9\n",
       "U.S.A.                          7\n",
       "United States of America        7\n",
       "Israel                          5\n",
       "Canada                          4\n",
       "UnitedStates                    2\n",
       "New Zealand                     2\n",
       "united States                   2\n",
       "United Kingdom                  2\n",
       "Brazil                          2\n",
       "France                          2\n",
       "U.S.A                           2\n",
       "Spain                           2\n",
       "United States of america        2\n",
       "Usa                             2\n",
       "U.S                             2\n",
       "India                           2\n",
       "Poland                          2\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We did filter for USD, so if we do a count of each unique country in descending count order, the relevant value(s) should show up at the top.\n",
    "df_salary_tech_usd['country'].value_counts()\n",
    "#show the top 30\n",
    "df_salary_tech_usd['country'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'United States', 'USA', 'United States of America',\n",
       "       'United States ', 'U.S. ', 'US ', 'usa', 'United states',\n",
       "       'United State of America', 'USA ', 'U.S.', 'us', 'Usa',\n",
       "       'united states', 'Uniyed states', 'U.S.A.', 'America',\n",
       "       'Puerto Rico ', 'U.s.', ' US', 'Unite States', 'Us',\n",
       "       'United State', 'Australia', 'Cuba', 'UnitedStates', 'Israel',\n",
       "       'United Stated', 'U.S', 'Usa ', 'Remote (philippines)',\n",
       "       'Singapore', 'United States Of America', 'Spain',\n",
       "       'United States of America ', 'Uruguay', 'United Kingdom',\n",
       "       'United Stateds', 'ISA', 'singapore', 'Pakistan', 'united States',\n",
       "       'Netherlands', 'San Francisco', 'United STates', 'U.S.A',\n",
       "       'United Stares', 'United States of america', 'Australian ',\n",
       "       'Unites States', 'U.S.A ', 'ss', 'Burma'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the unique countries with \"U\" and \"S\" in the name, or with \"America\" in the name.\n",
    "us_names = df_salary_tech_usd[df_salary_tech_usd['country'].str.contains('U|S|u|s|America')]['country'].unique()\n",
    "us_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['us', 'united states', 'usa', 'united states of america', 'united states', 'u.s.', 'us', 'usa', 'united states', 'united state of america', 'usa', 'u.s.', 'us', 'usa', 'united states', 'uniyed states', 'u.s.a.', 'america', 'puerto rico', 'u.s.', 'us', 'unite states', 'us', 'united state', 'unitedstates', 'united stated', 'u.s', 'usa', 'united states of america', 'united states of america', 'united stateds', 'united states', 'united states', 'u.s.a', 'united stares', 'united states of america', 'unites states', 'u.s.a']\n"
     ]
    }
   ],
   "source": [
    "#make all the names in the us_names list lowercase.\n",
    "us_names = [name.lower().strip() for name in us_names]\n",
    "#remove the names that arent: (make these lowercase too)['Singapore', 'Spain', 'Uruguay', 'United Kingdom', 'ISA', 'San Francisco', 'Puerto Rico ', 'Australia', 'Cuba', 'Israel', 'Remote (philippines)']]\n",
    "us_names = [name for name in us_names if name not in ['india', 'singapore', 'pakistan', 'spain', 'uruguay', 'united kingdom', 'isa', 'san francisco', 'puerto rico ', 'australia', 'cuba', 'israel', 'remote (philippines)', 'burma', 'ss', 'australian', 'netherlands']]\n",
    "print(us_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Well, we can’t get our answers with what we currently have, so you’ll have to make some changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s not worry about anything below the first 5 values for now. Convert the top 5 to a single canonical value―say, `'US'`, which is nice and short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sk/r_8fkf9s2ys9d8p1lfwj100r0000gn/T/ipykernel_50183/1953554997.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_salary_tech_usd['country'] = df_salary_tech_usd['country'].apply(lambda x: 'US' if x.lower().strip() in us_names else x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3727, 18)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace them all with 'US'.\n",
    "'''\n",
    "All the ways people have written United States of America:\n",
    "['US', 'United States', 'USA', 'United States of America', 'United States ', 'U.S. ', 'US ', 'United states', 'United State of America', 'USA ', 'U.S.', 'Usa', 'Uniyed states', 'U.S.A.', 'America', 'U.s.', ' US', 'Unite States', 'Us', 'United State', 'UnitedStates', 'United Stated', 'U.S', 'Usa ', 'United States Of America', 'United States of America ', 'United Stateds', 'united States', 'United STates', 'U.S.A', 'United Stares', 'United States of america', 'Unites States', 'U.S.A ',]\n",
    "'''\n",
    "#In the dataframe, if the country is in the us_names list, replace it with 'US'\n",
    "df_salary_tech_usd['country'] = df_salary_tech_usd['country'].apply(lambda x: 'US' if x.lower().strip() in us_names else x)\n",
    "#lose the rest of the countries\n",
    "df_salary_tech_usd = df_salary_tech_usd[df_salary_tech_usd['country'] == 'US']\n",
    "df_salary_tech_usd.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the count of each unique country again now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    3727\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count again.\n",
    "df_salary_tech_usd['country'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice anything interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I did it above.\n"
     ]
    }
   ],
   "source": [
    "# BONUS CREDIT: resolve [most of] those anomalous cases too without exhaustively taking every variant literally into account.\n",
    "print(\"I did it above.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States                1576\n",
      "USA                          1225\n",
      "US                            413\n",
      "U.S.                          108\n",
      "United States of America       90\n",
      "United States                  68\n",
      "Usa                            59\n",
      "USA                            56\n",
      "usa                            28\n",
      "United states                  23\n",
      "united states                  14\n",
      "Us                             12\n",
      "us                              9\n",
      "United States of America        7\n",
      "U.S.A.                          7\n",
      "United State of America         2\n",
      "Unite States                    2\n",
      "Usa                             2\n",
      "U.S                             2\n",
      "UnitedStates                    2\n",
      "united States                   2\n",
      "United States Of America        2\n",
      "U.S.                            2\n",
      "U.S.A                           2\n",
      "United States of america        2\n",
      "United Stares                   1\n",
      "United Stateds                  1\n",
      "Unites States                   1\n",
      "United STates                   1\n",
      "U.s.                            1\n",
      "United Stated                   1\n",
      "United State                    1\n",
      " US                             1\n",
      "Puerto Rico                     1\n",
      "America                         1\n",
      "Uniyed states                   1\n",
      "US                              1\n",
      "U.S.A                           1\n",
      "Name: country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# BONUS CREDIT: if you’ve resolved it, let’s see how well you did by counting the number of instances of each unique value.\n",
    "#gotta load the og\n",
    "df_salary_tech_og = pd.read_csv('data/df_salary_tech.csv')\n",
    "df_salary_tech_og['country'].value_counts()\n",
    "#do the lil value count thing\n",
    "#print the value counts of the country column if the value, lowered, and stripped, is in the us_names list. dont add the ones that arent in the list.\n",
    "df_salary_tech_us = df_salary_tech_og[df_salary_tech_og['country'].apply(lambda x: x.lower().strip() in us_names)]['country'].value_counts()\n",
    "\n",
    "#print the list of the unique names in df_salary_tech_us\n",
    "print(df_salary_tech_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s looking good so far. Let’s find out the minimum, mean, and maximum (in that order) salary by state, sorted by the mean in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert 75,00070,00072,00052,00029,120105,000120,00052000550009500035000035000 to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1791\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1791\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maggregate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1801\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1802\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/ops.py:1039\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[0;32m-> 1039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcy_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcython_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomp_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mngroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mngroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/ops.py:708\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[0;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[1;32m    701\u001b[0m         values,\n\u001b[1;32m    702\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    706\u001b[0m     )\n\u001b[0;32m--> 708\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_op_ndim_compat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mngroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mngroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomp_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomp_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/ops.py:512\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m     result_mask \u001b[38;5;241m=\u001b[39m result_mask[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[0;32m--> 512\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_cython_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mngroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mngroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomp_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomp_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/ops.py:571\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m out_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[0;32m--> 571\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_cython_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_numeric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    572\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_vals(values)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/ops.py:192\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[0;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39m__signatures__:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;66;03m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction is not implemented for this dtype: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m     )\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/nanops.py:1630\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1630\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1632\u001b[0m     \u001b[38;5;66;03m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '75,00070,00072,00052,00029,120105,000120,00052000550009500035000035000'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/nanops.py:1634\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1634\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcomplex\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1636\u001b[0m     \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Find the minimum, mean, and maximum salary in USD by U.S. state. (use the df_salary_tech_usd variable)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf_salary_tech_usd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msalary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/generic.py:281\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, abc\u001b[38;5;241m.\u001b[39mIterable):\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[0;32m--> 281\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_multiple_funcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/generic.py:336\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[1;32m    335\u001b[0m     key \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mOutputKey(label\u001b[38;5;241m=\u001b[39mname, position\u001b[38;5;241m=\u001b[39midx)\n\u001b[0;32m--> 336\u001b[0m     results[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/generic.py:275\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, abc\u001b[38;5;241m.\u001b[39mIterable):\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:2183\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[1;32m   2182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2183\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2185\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only_bool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1810\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;66;03m# TypeError -> we may have an exception in trying to aggregate\u001b[39;00m\n\u001b[1;32m   1809\u001b[0m \u001b[38;5;66;03m#  continue and exclude the block\u001b[39;00m\n\u001b[0;32m-> 1810\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_failures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_failures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_ser \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_mgr) \u001b[38;5;241m<\u001b[39m orig_len:\n\u001b[1;32m   1813\u001b[0m     warn_dropping_nuisance_columns_deprecated(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), how, numeric_only)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/internals/base.py:199\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[0;34m(self, func, ignore_failures)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03mignore_failures : bool, default False\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    Not used; for compatibility with ArrayManager/BlockManager.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\n\u001b[0;32m--> 199\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[1;32m    202\u001b[0m mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1804\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1791\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[1;32m   1792\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1793\u001b[0m         values,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1798\u001b[0m     )\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1801\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1802\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[0;32m-> 1804\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1745\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1740\u001b[0m     ser \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;66;03m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, Categorical):\n\u001b[1;32m   1748\u001b[0m     \u001b[38;5;66;03m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(values)\u001b[38;5;241m.\u001b[39m_from_sequence(res_values, dtype\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/ops.py:1081\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m   1078\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1081\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1083\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/ops.py:1104\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m   1101\u001b[0m splitter \u001b[38;5;241m=\u001b[39m get_splitter(obj, ids, ngroups, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[0;32m-> 1104\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m     res \u001b[38;5;241m=\u001b[39m libreduction\u001b[38;5;241m.\u001b[39mextract_result(res)\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[1;32m   1108\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:2185\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[1;32m   2182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2183\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   2184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m-> 2185\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only_bool\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   2186\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   2187\u001b[0m     )\n\u001b[1;32m   2188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/nanops.py:1637\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1634\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[1;32m   1635\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1636\u001b[0m             \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n\u001b[0;32m-> 1637\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert 75,00070,00072,00052,00029,120105,000120,00052000550009500035000035000 to numeric"
     ]
    }
   ],
   "source": [
    "# Find the minimum, mean, and maximum salary in USD by U.S. state. (use the df_salary_tech_usd variable)\n",
    "df_salary_tech_usd.groupby('state')['salary'].agg(['min', 'mean', 'max']).sort_values('mean', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, pooh! We forgot that `salary` isn’t numeric. Something wrong must be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:03:01</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Systems Analyst</td>\n",
       "      <td>Data developer/ETL Developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:04:04</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Principal Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:04:04</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Intelligence Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Around 20,000 a year in stock</td>\n",
       "      <td>US</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:04:07</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Mobile developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4/27/2021 11:04:09</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Product Design Director</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Chapel Hill</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>5/27/2024 2:47:26</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Lead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2600000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Newyork</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Man</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>6/3/2024 16:15:43</td>\n",
       "      <td>18-24</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Research Data Analyst Associate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Evanston</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>1 year or less</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>7/1/2024 20:05:58</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Junior data analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Black or African American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>7/3/2024 14:02:01</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Senior Global Public Relations Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144000.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boise-but remote. Company located in Boston</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4700</th>\n",
       "      <td>7/23/2024 17:51:03</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Systems Architect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3727 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    age           industry  \\\n",
       "1     4/27/2021 11:03:01  45-54  Computing or Tech   \n",
       "2     4/27/2021 11:04:04  25-34  Computing or Tech   \n",
       "3     4/27/2021 11:04:04  25-34  Computing or Tech   \n",
       "4     4/27/2021 11:04:07  35-44  Computing or Tech   \n",
       "5     4/27/2021 11:04:09  35-44  Computing or Tech   \n",
       "...                  ...    ...                ...   \n",
       "4695   5/27/2024 2:47:26  25-34  Computing or Tech   \n",
       "4696   6/3/2024 16:15:43  18-24  Computing or Tech   \n",
       "4698   7/1/2024 20:05:58  25-34  Computing or Tech   \n",
       "4699   7/3/2024 14:02:01  25-34  Computing or Tech   \n",
       "4700  7/23/2024 17:51:03  25-34  Computing or Tech   \n",
       "\n",
       "                                       title                 title_context  \\\n",
       "1                            Systems Analyst  Data developer/ETL Developer   \n",
       "2                Principal Software Engineer                           NaN   \n",
       "3                       Intelligence Analyst                           NaN   \n",
       "4                           Mobile developer                           NaN   \n",
       "5                    Product Design Director                           NaN   \n",
       "...                                      ...                           ...   \n",
       "4695                                    Lead                           NaN   \n",
       "4696         Research Data Analyst Associate                           NaN   \n",
       "4698                    Junior data analyst                            NaN   \n",
       "4699  Senior Global Public Relations Manager                           NaN   \n",
       "4700                       Systems Architect                           NaN   \n",
       "\n",
       "         salary  additional_compensation currency other_currency  \\\n",
       "1           NaN                  10000.0      USD            NaN   \n",
       "2           NaN                   5000.0      USD            NaN   \n",
       "3           NaN                  20000.0      USD            NaN   \n",
       "4           NaN                   2500.0      USD            NaN   \n",
       "5           NaN                  40000.0      USD            NaN   \n",
       "...         ...                      ...      ...            ...   \n",
       "4695  2600000.0                      NaN      USD            NaN   \n",
       "4696    60000.0                      0.0      USD            NaN   \n",
       "4698    35000.0                  15000.0      USD            NaN   \n",
       "4699   144000.0                  15000.0      USD            NaN   \n",
       "4700   109000.0                      NaN      USD            NaN   \n",
       "\n",
       "                     salary_context country           state  \\\n",
       "1                               NaN      US        Missouri   \n",
       "2                               NaN      US    Pennsylvania   \n",
       "3     Around 20,000 a year in stock      US        Virginia   \n",
       "4                               NaN      US   Massachusetts   \n",
       "5                               NaN      US  North Carolina   \n",
       "...                             ...     ...             ...   \n",
       "4695                            NaN      US         Florida   \n",
       "4696                            NaN      US        Illinois   \n",
       "4698                            NaN      US         Alabama   \n",
       "4699                            NaN      US   Massachusetts   \n",
       "4700                            NaN      US         Georgia   \n",
       "\n",
       "                                              city      total_yoe  \\\n",
       "1                                        St. Louis  21 - 30 years   \n",
       "2                                       Pittsburgh   8 - 10 years   \n",
       "3                                    Arlington, VA   8 - 10 years   \n",
       "4                                           Boston      5-7 years   \n",
       "5                                      Chapel Hill  11 - 20 years   \n",
       "...                                            ...            ...   \n",
       "4695                                       Newyork   8 - 10 years   \n",
       "4696                                      Evanston    2 - 4 years   \n",
       "4698                                      Alabama     2 - 4 years   \n",
       "4699  Boise-but remote. Company located in Boston    8 - 10 years   \n",
       "4700                                       Atlanta      5-7 years   \n",
       "\n",
       "           field_yoe highest_education_completed gender  \\\n",
       "1      21 - 30 years              College degree  Woman   \n",
       "2          5-7 years              College degree  Woman   \n",
       "3       8 - 10 years             Master's degree    Man   \n",
       "4          5-7 years                         PhD  Woman   \n",
       "5      11 - 20 years              College degree  Woman   \n",
       "...              ...                         ...    ...   \n",
       "4695     2 - 4 years                         NaN    Man   \n",
       "4696  1 year or less              College degree  Woman   \n",
       "4698     2 - 4 years              College degree  Woman   \n",
       "4699    8 - 10 years             Master's degree  Woman   \n",
       "4700       5-7 years              College degree    Man   \n",
       "\n",
       "                           race  \n",
       "1                         White  \n",
       "2                         White  \n",
       "3                         White  \n",
       "4                         White  \n",
       "5                         White  \n",
       "...                         ...  \n",
       "4695                        NaN  \n",
       "4696                      White  \n",
       "4698  Black or African American  \n",
       "4699                      White  \n",
       "4700                      White  \n",
       "\n",
       "[3727 rows x 18 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix it.\n",
    "#convert the salary column to numeric and drop the rows with invalid values.\n",
    "df_salary_tech_usd['salary'] = pd.to_numeric(df_salary_tech_usd['salary'], errors='coerce')\n",
    "df_salary_tech_usd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP THE rows with Nan values but only in the salary column.  \n",
    "df_salary_tech_usd = df_salary_tech_usd.dropna(subset=['salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>4/27/2021 17:02:03</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Software Development Lead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Madison</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>4/28/2021 6:41:31</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Account Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Base + commission</td>\n",
       "      <td>US</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>4/28/2021 16:45:53</td>\n",
       "      <td>18-24</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Product Marketer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Start up without funding. Compensation is in s...</td>\n",
       "      <td>US</td>\n",
       "      <td>California</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>1 year or less</td>\n",
       "      <td>1 year or less</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>Asian or Asian American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>4/28/2021 17:22:37</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Chief Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Additional compensation is expected value of o...</td>\n",
       "      <td>US</td>\n",
       "      <td>California</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>4/28/2021 22:49:19</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Technical Writer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Silverdale</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>5/27/2024 2:47:26</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Lead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2600000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Newyork</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Man</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>6/3/2024 16:15:43</td>\n",
       "      <td>18-24</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Research Data Analyst Associate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Evanston</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>1 year or less</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>7/1/2024 20:05:58</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Junior data analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Black or African American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>7/3/2024 14:02:01</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Senior Global Public Relations Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144000.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boise-but remote. Company located in Boston</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4700</th>\n",
       "      <td>7/23/2024 17:51:03</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Systems Architect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1021 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    age           industry  \\\n",
       "1029  4/27/2021 17:02:03  35-44  Computing or Tech   \n",
       "1493   4/28/2021 6:41:31  45-54  Computing or Tech   \n",
       "2048  4/28/2021 16:45:53  18-24  Computing or Tech   \n",
       "2198  4/28/2021 17:22:37  25-34  Computing or Tech   \n",
       "2782  4/28/2021 22:49:19  25-34  Computing or Tech   \n",
       "...                  ...    ...                ...   \n",
       "4695   5/27/2024 2:47:26  25-34  Computing or Tech   \n",
       "4696   6/3/2024 16:15:43  18-24  Computing or Tech   \n",
       "4698   7/1/2024 20:05:58  25-34  Computing or Tech   \n",
       "4699   7/3/2024 14:02:01  25-34  Computing or Tech   \n",
       "4700  7/23/2024 17:51:03  25-34  Computing or Tech   \n",
       "\n",
       "                                       title title_context     salary  \\\n",
       "1029               Software Development Lead           NaN        1.0   \n",
       "1493                         Account Manager           NaN       55.0   \n",
       "2048                        Product Marketer           NaN        0.0   \n",
       "2198                    Chief Data Scientist           NaN      240.0   \n",
       "2782                        Technical Writer           NaN       72.0   \n",
       "...                                      ...           ...        ...   \n",
       "4695                                    Lead           NaN  2600000.0   \n",
       "4696         Research Data Analyst Associate           NaN    60000.0   \n",
       "4698                    Junior data analyst            NaN    35000.0   \n",
       "4699  Senior Global Public Relations Manager           NaN   144000.0   \n",
       "4700                       Systems Architect           NaN   109000.0   \n",
       "\n",
       "      additional_compensation currency other_currency  \\\n",
       "1029                 130000.0      USD            NaN   \n",
       "1493                     12.0      USD            NaN   \n",
       "2048                      0.0      USD            NaN   \n",
       "2198                    100.0      USD            NaN   \n",
       "2782                      0.0      USD            NaN   \n",
       "...                       ...      ...            ...   \n",
       "4695                      NaN      USD            NaN   \n",
       "4696                      0.0      USD            NaN   \n",
       "4698                  15000.0      USD            NaN   \n",
       "4699                  15000.0      USD            NaN   \n",
       "4700                      NaN      USD            NaN   \n",
       "\n",
       "                                         salary_context country  \\\n",
       "1029                                                NaN      US   \n",
       "1493                                  Base + commission      US   \n",
       "2048  Start up without funding. Compensation is in s...      US   \n",
       "2198  Additional compensation is expected value of o...      US   \n",
       "2782                                                NaN      US   \n",
       "...                                                 ...     ...   \n",
       "4695                                                NaN      US   \n",
       "4696                                                NaN      US   \n",
       "4698                                                NaN      US   \n",
       "4699                                                NaN      US   \n",
       "4700                                                NaN      US   \n",
       "\n",
       "              state                                          city  \\\n",
       "1029      Wisconsin                                       Madison   \n",
       "1493  New Hampshire                                    Manchester   \n",
       "2048     California                                   Santa Clara   \n",
       "2198     California                                       Oakland   \n",
       "2782     Washington                                    Silverdale   \n",
       "...             ...                                           ...   \n",
       "4695        Florida                                       Newyork   \n",
       "4696       Illinois                                      Evanston   \n",
       "4698        Alabama                                      Alabama    \n",
       "4699  Massachusetts  Boise-but remote. Company located in Boston    \n",
       "4700        Georgia                                       Atlanta   \n",
       "\n",
       "           total_yoe       field_yoe highest_education_completed gender  \\\n",
       "1029    8 - 10 years    8 - 10 years             Master's degree    Man   \n",
       "1493   21 - 30 years    8 - 10 years              College degree  Woman   \n",
       "2048  1 year or less  1 year or less              College degree    Man   \n",
       "2198       5-7 years       5-7 years                         PhD    Man   \n",
       "2782    8 - 10 years     2 - 4 years              College degree  Woman   \n",
       "...              ...             ...                         ...    ...   \n",
       "4695    8 - 10 years     2 - 4 years                         NaN    Man   \n",
       "4696     2 - 4 years  1 year or less              College degree  Woman   \n",
       "4698     2 - 4 years     2 - 4 years              College degree  Woman   \n",
       "4699    8 - 10 years    8 - 10 years             Master's degree  Woman   \n",
       "4700       5-7 years       5-7 years              College degree    Man   \n",
       "\n",
       "                           race  \n",
       "1029                      White  \n",
       "1493                      White  \n",
       "2048    Asian or Asian American  \n",
       "2198                      White  \n",
       "2782                      White  \n",
       "...                         ...  \n",
       "4695                        NaN  \n",
       "4696                      White  \n",
       "4698  Black or African American  \n",
       "4699                      White  \n",
       "4700                      White  \n",
       "\n",
       "[1021 rows x 18 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_salary_tech_usd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try that again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [timestamp, age, industry, title, title_context, salary, additional_compensation, currency, other_currency, salary_context, country, state, city, total_yoe, field_yoe, highest_education_completed, gender, race]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_salary_tech_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Michigan, Texas, Washington</th>\n",
       "      <td>340000.0</td>\n",
       "      <td>340000.000000</td>\n",
       "      <td>340000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>28800.0</td>\n",
       "      <td>210711.000000</td>\n",
       "      <td>2600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California, Oregon</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California, Colorado</th>\n",
       "      <td>176000.0</td>\n",
       "      <td>176000.000000</td>\n",
       "      <td>176000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>169000.0</td>\n",
       "      <td>169000.000000</td>\n",
       "      <td>169000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>68000.0</td>\n",
       "      <td>161610.000000</td>\n",
       "      <td>270000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>0.0</td>\n",
       "      <td>153286.988827</td>\n",
       "      <td>520000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>14000.0</td>\n",
       "      <td>146594.112150</td>\n",
       "      <td>590000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>1.0</td>\n",
       "      <td>145806.888889</td>\n",
       "      <td>920000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>59000.0</td>\n",
       "      <td>142923.076923</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey, New York</th>\n",
       "      <td>135000.0</td>\n",
       "      <td>137500.000000</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>42000.0</td>\n",
       "      <td>137066.666667</td>\n",
       "      <td>954000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>72.0</td>\n",
       "      <td>136923.916667</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>41000.0</td>\n",
       "      <td>125899.155844</td>\n",
       "      <td>400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>107100.0</td>\n",
       "      <td>124550.000000</td>\n",
       "      <td>142000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>67500.0</td>\n",
       "      <td>124090.909091</td>\n",
       "      <td>192000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>16200.0</td>\n",
       "      <td>122640.000000</td>\n",
       "      <td>230000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>62000.0</td>\n",
       "      <td>119955.461538</td>\n",
       "      <td>176000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>36000.0</td>\n",
       "      <td>117555.571429</td>\n",
       "      <td>228800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>117400.000000</td>\n",
       "      <td>350000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana, Washington</th>\n",
       "      <td>117000.0</td>\n",
       "      <td>117000.000000</td>\n",
       "      <td>117000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>52000.0</td>\n",
       "      <td>116826.388889</td>\n",
       "      <td>237000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>29120.0</td>\n",
       "      <td>115297.647059</td>\n",
       "      <td>242000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>58750.0</td>\n",
       "      <td>115086.696970</td>\n",
       "      <td>378000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montana</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>112666.666667</td>\n",
       "      <td>145000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>41500.0</td>\n",
       "      <td>109666.666667</td>\n",
       "      <td>167000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>49400.0</td>\n",
       "      <td>109291.891892</td>\n",
       "      <td>165000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia, Virginia</th>\n",
       "      <td>109200.0</td>\n",
       "      <td>109200.000000</td>\n",
       "      <td>109200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermont</th>\n",
       "      <td>91250.0</td>\n",
       "      <td>105625.000000</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>74860.0</td>\n",
       "      <td>105465.000000</td>\n",
       "      <td>170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>33280.0</td>\n",
       "      <td>105023.333333</td>\n",
       "      <td>176000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maine</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>103833.333333</td>\n",
       "      <td>173000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>103685.245902</td>\n",
       "      <td>190000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kentucky</th>\n",
       "      <td>62000.0</td>\n",
       "      <td>102500.000000</td>\n",
       "      <td>125000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iowa</th>\n",
       "      <td>63000.0</td>\n",
       "      <td>101200.000000</td>\n",
       "      <td>142000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>52124.0</td>\n",
       "      <td>101064.941176</td>\n",
       "      <td>210000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhode Island</th>\n",
       "      <td>76000.0</td>\n",
       "      <td>99475.000000</td>\n",
       "      <td>122950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>29000.0</td>\n",
       "      <td>97841.666667</td>\n",
       "      <td>165000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>97833.333333</td>\n",
       "      <td>145000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>41600.0</td>\n",
       "      <td>95758.823529</td>\n",
       "      <td>235000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>82000.0</td>\n",
       "      <td>95733.333333</td>\n",
       "      <td>115200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>61500.0</td>\n",
       "      <td>91750.000000</td>\n",
       "      <td>144000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>55.0</td>\n",
       "      <td>87175.833333</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>36958.0</td>\n",
       "      <td>84802.571429</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>82875.000000</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California, Maryland</th>\n",
       "      <td>81500.0</td>\n",
       "      <td>81500.000000</td>\n",
       "      <td>81500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>75000.0</td>\n",
       "      <td>80500.000000</td>\n",
       "      <td>84000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missouri</th>\n",
       "      <td>80.0</td>\n",
       "      <td>80339.923077</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>77333.333333</td>\n",
       "      <td>95000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>43000.0</td>\n",
       "      <td>76736.000000</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Carolina</th>\n",
       "      <td>40000.0</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     min           mean        max\n",
       "state                                                             \n",
       "Michigan, Texas, Washington     340000.0  340000.000000   340000.0\n",
       "Florida                          28800.0  210711.000000  2600000.0\n",
       "California, Oregon              200000.0  200000.000000   200000.0\n",
       "California, Colorado            176000.0  176000.000000   176000.0\n",
       "Delaware                        169000.0  169000.000000   169000.0\n",
       "Connecticut                      68000.0  161610.000000   270000.0\n",
       "California                           0.0  153286.988827   520000.0\n",
       "New York                         14000.0  146594.112150   590000.0\n",
       "Wisconsin                            1.0  145806.888889   920000.0\n",
       "District of Columbia             59000.0  142923.076923   200000.0\n",
       "New Jersey, New York            135000.0  137500.000000   140000.0\n",
       "Ohio                             42000.0  137066.666667   954000.0\n",
       "Washington                          72.0  136923.916667   300000.0\n",
       "Massachusetts                    41000.0  125899.155844   400000.0\n",
       "Nevada                          107100.0  124550.000000   142000.0\n",
       "New Jersey                       67500.0  124090.909091   192000.0\n",
       "Oregon                           16200.0  122640.000000   230000.0\n",
       "West Virginia                   120000.0  120000.000000   120000.0\n",
       "Maryland                         62000.0  119955.461538   176000.0\n",
       "Illinois                         36000.0  117555.571429   228800.0\n",
       "Alabama                          35000.0  117400.000000   350000.0\n",
       "Louisiana, Washington           117000.0  117000.000000   117000.0\n",
       "Pennsylvania                     52000.0  116826.388889   237000.0\n",
       "Georgia                          29120.0  115297.647059   242000.0\n",
       "Virginia                         58750.0  115086.696970   378000.0\n",
       "Montana                          65000.0  112666.666667   145000.0\n",
       "Kansas                           41500.0  109666.666667   167000.0\n",
       "Colorado                         49400.0  109291.891892   165000.0\n",
       "District of Columbia, Virginia  109200.0  109200.000000   109200.0\n",
       "Vermont                          91250.0  105625.000000   120000.0\n",
       "Idaho                            74860.0  105465.000000   170000.0\n",
       "Utah                             33280.0  105023.333333   176000.0\n",
       "Maine                            50000.0  103833.333333   173000.0\n",
       "Texas                            10700.0  103685.245902   190000.0\n",
       "Kentucky                         62000.0  102500.000000   125000.0\n",
       "Iowa                             63000.0  101200.000000   142000.0\n",
       "Minnesota                        52124.0  101064.941176   210000.0\n",
       "Rhode Island                     76000.0   99475.000000   122950.0\n",
       "North Carolina                   29000.0   97841.666667   165000.0\n",
       "Arizona                          35000.0   97833.333333   145000.0\n",
       "Michigan                         41600.0   95758.823529   235000.0\n",
       "New Mexico                       82000.0   95733.333333   115200.0\n",
       "Tennessee                        61500.0   91750.000000   144000.0\n",
       "New Hampshire                       55.0   87175.833333   130000.0\n",
       "Oklahoma                         36958.0   84802.571429   180000.0\n",
       "Indiana                          15000.0   82875.000000   140000.0\n",
       "California, Maryland             81500.0   81500.000000    81500.0\n",
       "Louisiana                        75000.0   80500.000000    84000.0\n",
       "Missouri                            80.0   80339.923077   200000.0\n",
       "Arkansas                         60000.0   77333.333333    95000.0\n",
       "Nebraska                         43000.0   76736.000000   140000.0\n",
       "South Carolina                   40000.0   40000.000000    40000.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try it again. Yeah!\n",
    "df_salary_tech_usd.groupby('state')['salary'].agg(['min', 'mean', 'max']).sort_values('mean', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did the trick! Now let’s narrow this to data 2021 and 2022 just because (lel). *(Hint: that timestamp column may not be a temporal type right now.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sk/r_8fkf9s2ys9d8p1lfwj100r0000gn/T/ipykernel_50183/629237399.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_salary_tech_usd['timestamp'] = pd.to_datetime(df_salary_tech_usd['timestamp'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Filter the data to within 2021, 2022, or 2023, saving the DataFrame to a new variable, and generate the summary again.\n",
    "#convert the timestamp column to datetime.\n",
    "df_salary_tech_usd['timestamp'] = pd.to_datetime(df_salary_tech_usd['timestamp'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary_tech_usd_time = df_salary_tech_usd.dropna(subset=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary_tech_usd_time = df_salary_tech_usd_time[df_salary_tech_usd_time['timestamp'].dt.year.isin([2021, 2022, 2023])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>2021-04-27 17:02:03</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Software Development Lead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Madison</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>2021-04-28 06:41:31</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Account Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Base + commission</td>\n",
       "      <td>US</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>2021-04-28 16:45:53</td>\n",
       "      <td>18-24</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Product Marketer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Start up without funding. Compensation is in s...</td>\n",
       "      <td>US</td>\n",
       "      <td>California</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>1 year or less</td>\n",
       "      <td>1 year or less</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>Asian or Asian American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>2021-04-28 17:22:37</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Chief Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Additional compensation is expected value of o...</td>\n",
       "      <td>US</td>\n",
       "      <td>California</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>2021-04-28 22:49:19</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Technical Writer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Silverdale</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4678</th>\n",
       "      <td>2023-03-28 18:41:56</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Software Engineer II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116421.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>Bethesda</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4679</th>\n",
       "      <td>2023-04-18 09:26:31</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Porting Agent</td>\n",
       "      <td>Port phone numbers from one carrier to another</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>Some college</td>\n",
       "      <td>Man</td>\n",
       "      <td>Hispanic, Latino, or Spanish origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4680</th>\n",
       "      <td>2023-05-09 17:57:30</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>1 year or less</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>2023-05-28 16:10:53</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>New York</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>Black or African American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>2023-09-08 12:35:45</td>\n",
       "      <td>18-24</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>intern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>1 year or less</td>\n",
       "      <td>1 year or less</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>Asian or Asian American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1011 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    age           industry                      title  \\\n",
       "1029 2021-04-27 17:02:03  35-44  Computing or Tech  Software Development Lead   \n",
       "1493 2021-04-28 06:41:31  45-54  Computing or Tech            Account Manager   \n",
       "2048 2021-04-28 16:45:53  18-24  Computing or Tech           Product Marketer   \n",
       "2198 2021-04-28 17:22:37  25-34  Computing or Tech       Chief Data Scientist   \n",
       "2782 2021-04-28 22:49:19  25-34  Computing or Tech           Technical Writer   \n",
       "...                  ...    ...                ...                        ...   \n",
       "4678 2023-03-28 18:41:56  25-34  Computing or Tech       Software Engineer II   \n",
       "4679 2023-04-18 09:26:31  35-44  Computing or Tech              Porting Agent   \n",
       "4680 2023-05-09 17:57:30  45-54  Computing or Tech        Junior Data Analyst   \n",
       "4681 2023-05-28 16:10:53  45-54  Computing or Tech               Data Analyst   \n",
       "4684 2023-09-08 12:35:45  18-24  Computing or Tech                     intern   \n",
       "\n",
       "                                       title_context    salary  \\\n",
       "1029                                             NaN       1.0   \n",
       "1493                                             NaN      55.0   \n",
       "2048                                             NaN       0.0   \n",
       "2198                                             NaN     240.0   \n",
       "2782                                             NaN      72.0   \n",
       "...                                              ...       ...   \n",
       "4678                                             NaN  116421.0   \n",
       "4679  Port phone numbers from one carrier to another   60000.0   \n",
       "4680                                             NaN   65000.0   \n",
       "4681                                             NaN   65000.0   \n",
       "4684                                             NaN   35000.0   \n",
       "\n",
       "      additional_compensation currency other_currency  \\\n",
       "1029                 130000.0      USD            NaN   \n",
       "1493                     12.0      USD            NaN   \n",
       "2048                      0.0      USD            NaN   \n",
       "2198                    100.0      USD            NaN   \n",
       "2782                      0.0      USD            NaN   \n",
       "...                       ...      ...            ...   \n",
       "4678                   3000.0      USD            NaN   \n",
       "4679                   5000.0      USD            NaN   \n",
       "4680                      0.0      USD            NaN   \n",
       "4681                      0.0      USD            NaN   \n",
       "4684                      0.0      USD            NaN   \n",
       "\n",
       "                                         salary_context country  \\\n",
       "1029                                                NaN      US   \n",
       "1493                                  Base + commission      US   \n",
       "2048  Start up without funding. Compensation is in s...      US   \n",
       "2198  Additional compensation is expected value of o...      US   \n",
       "2782                                                NaN      US   \n",
       "...                                                 ...     ...   \n",
       "4678                                                NaN      US   \n",
       "4679                                                NaN      US   \n",
       "4680                                                NaN      US   \n",
       "4681                                                NaN      US   \n",
       "4684                                                NaN      US   \n",
       "\n",
       "              state         city       total_yoe       field_yoe  \\\n",
       "1029      Wisconsin      Madison    8 - 10 years    8 - 10 years   \n",
       "1493  New Hampshire   Manchester   21 - 30 years    8 - 10 years   \n",
       "2048     California  Santa Clara  1 year or less  1 year or less   \n",
       "2198     California      Oakland       5-7 years       5-7 years   \n",
       "2782     Washington   Silverdale    8 - 10 years     2 - 4 years   \n",
       "...             ...          ...             ...             ...   \n",
       "4678       Maryland     Bethesda     2 - 4 years     2 - 4 years   \n",
       "4679        Georgia      Atlanta   21 - 30 years     2 - 4 years   \n",
       "4680       Virginia     Richmond   21 - 30 years  1 year or less   \n",
       "4681       New York        Bronx   21 - 30 years    8 - 10 years   \n",
       "4684          Texas       Dallas  1 year or less  1 year or less   \n",
       "\n",
       "     highest_education_completed gender                                 race  \n",
       "1029             Master's degree    Man                                White  \n",
       "1493              College degree  Woman                                White  \n",
       "2048              College degree    Man              Asian or Asian American  \n",
       "2198                         PhD    Man                                White  \n",
       "2782              College degree  Woman                                White  \n",
       "...                          ...    ...                                  ...  \n",
       "4678              College degree    Man                                White  \n",
       "4679                Some college    Man  Hispanic, Latino, or Spanish origin  \n",
       "4680              College degree    Man                                White  \n",
       "4681              College degree    Man            Black or African American  \n",
       "4684             Master's degree    Man              Asian or Asian American  \n",
       "\n",
       "[1011 rows x 18 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_salary_tech_usd_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Clearly, we do not have enough data to produce useful figures for the level of specificity you’ve now reached. What do you notice about Delaware and West Virginia?\n",
    "\n",
    "Let’s back out a bit and return to `df_salary` (which was the loaded data with renamed columns but *sans* filtering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #0\n",
    "\n",
    "Apply the same steps as before to `df_salary`, but do not filter for any specific industry. Do perform the other data cleaning stuff, and get to a point where you can generate the minimum, mean, and maximum by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #1\n",
    "\n",
    "This time, format the table output nicely (*$12,345.00*) without modifying the values in the `DataFrame`. That is, `df_salary` should be identical before versus after running your code.\n",
    "\n",
    "(*Hint: if you run into an error about `jinja2` perhaps you need to `pip install` something.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #2\n",
    "\n",
    "Filter out the non-single-states (e.g., `'California, Colorado'`) in the most elegant way possible (i.e., *not* by blacklisting all the bad values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #3\n",
    "\n",
    "Show the quantiles instead of just minimum, mean, and maximum―say 0%, 5%, 25%, 50%, 75%, 95%, and 100%. Outliers may be deceiving.\n",
    "\n",
    "Sort by whatever interests you―like say the *50th* percentile.\n",
    "\n",
    "And throw in a count by state too. It would be interesting to know how many data points contribute to the figures for each state. (*Hint: your nice formatting from Bonus #1 might not work this time around.* 😜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
